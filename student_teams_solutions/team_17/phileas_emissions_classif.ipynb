{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e63677a7-9f7d-4a2a-bfb9-220091b50c3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predicting emissions : classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a836962-eb03-47f8-a0de-439a4f4b2ce8",
   "metadata": {},
   "source": [
    "## Simple CNN from the original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94fb0c90-fabc-42dd-9e5c-b9a8bbd4f450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>im_name</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>class</th>\n",
       "      <th>models</th>\n",
       "      <th>model_e</th>\n",
       "      <th>Brand</th>\n",
       "      <th>year</th>\n",
       "      <th>Average Urban Consumption</th>\n",
       "      <th>Average extra-urban consumption</th>\n",
       "      <th>Average mixed consumption</th>\n",
       "      <th>Average of CO2 (g per km)</th>\n",
       "      <th>Average CO type I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107347968.jpg</td>\n",
       "      <td>40.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>car</td>\n",
       "      <td>Audi S5 Convertible 2012</td>\n",
       "      <td>11</td>\n",
       "      <td>Audi</td>\n",
       "      <td>2012</td>\n",
       "      <td>7.90636</td>\n",
       "      <td>5.3053</td>\n",
       "      <td>6.262544</td>\n",
       "      <td>153.533569</td>\n",
       "      <td>0,298187279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109641728.jpg</td>\n",
       "      <td>278.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>car</td>\n",
       "      <td>Audi S5 Convertible 2012</td>\n",
       "      <td>11</td>\n",
       "      <td>Audi</td>\n",
       "      <td>2012</td>\n",
       "      <td>7.90636</td>\n",
       "      <td>5.3053</td>\n",
       "      <td>6.262544</td>\n",
       "      <td>153.533569</td>\n",
       "      <td>0,298187279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111214592.jpg</td>\n",
       "      <td>29.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>car</td>\n",
       "      <td>Audi S5 Convertible 2012</td>\n",
       "      <td>11</td>\n",
       "      <td>Audi</td>\n",
       "      <td>2012</td>\n",
       "      <td>7.90636</td>\n",
       "      <td>5.3053</td>\n",
       "      <td>6.262544</td>\n",
       "      <td>153.533569</td>\n",
       "      <td>0,298187279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110821376.jpg</td>\n",
       "      <td>34.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>car</td>\n",
       "      <td>Audi S5 Convertible 2012</td>\n",
       "      <td>11</td>\n",
       "      <td>Audi</td>\n",
       "      <td>2012</td>\n",
       "      <td>7.90636</td>\n",
       "      <td>5.3053</td>\n",
       "      <td>6.262544</td>\n",
       "      <td>153.533569</td>\n",
       "      <td>0,298187279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109379584.jpg</td>\n",
       "      <td>99.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>712.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>car</td>\n",
       "      <td>Audi S5 Convertible 2012</td>\n",
       "      <td>11</td>\n",
       "      <td>Audi</td>\n",
       "      <td>2012</td>\n",
       "      <td>7.90636</td>\n",
       "      <td>5.3053</td>\n",
       "      <td>6.262544</td>\n",
       "      <td>153.533569</td>\n",
       "      <td>0,298187279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         im_name  x_min  ...  Average of CO2 (g per km)  Average CO type I\n",
       "0  107347968.jpg   40.0  ...                 153.533569        0,298187279\n",
       "1  109641728.jpg  278.0  ...                 153.533569        0,298187279\n",
       "2  111214592.jpg   29.0  ...                 153.533569        0,298187279\n",
       "3  110821376.jpg   34.0  ...                 153.533569        0,298187279\n",
       "4  109379584.jpg   99.0  ...                 153.533569        0,298187279\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "emission_data = pd.read_csv(\"../datasets/car_models_footprint.csv\", sep=\";\")\n",
    "\n",
    "path_annotrain = \"../datasets/datasets_train/train_annotation/_annotation.csv\"\n",
    "\n",
    "train_annotation = pd.read_csv(path_annotrain, index_col=0)\n",
    "train_annotation = train_annotation[train_annotation[\"models\"]!=\" \"]\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_annotation[\"model_e\"] = le.fit_transform(train_annotation[\"models\"])\n",
    "\n",
    "n_classes = train_annotation[\"model_e\"].max()+1\n",
    "\n",
    "df = pd.merge(train_annotation, emission_data, \"inner\", on=\"models\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed499b2-9ca9-407c-b655-0f870c3fd2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification baseline : 0.019098548510313215\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Classification baseline :\", accuracy_score([df[\"model_e\"].mode() for _ in range(df.shape[0])], \n",
    "                                                  df[\"model_e\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c0d273-8ca9-4568-8a13-68814123611b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model\n",
      "epoch 0 : train loss 4.62913, train accuracy 0.76, val loss 4.60622, val accuracy 0.38, time 29.36s\n",
      "Saving best model\n",
      "epoch 1 : train loss 4.56664, train accuracy 2.01, val loss 4.61004, val accuracy 1.91, time 20.38s\n",
      "Saving best model\n",
      "epoch 2 : train loss 4.55984, train accuracy 1.81, val loss 4.61245, val accuracy 1.91, time 31.03s\n",
      "epoch 3 : train loss 4.55815, train accuracy 1.72, val loss 4.61203, val accuracy 1.15, time 20.43s\n",
      "epoch 4 : train loss 4.56268, train accuracy 1.53, val loss 4.61397, val accuracy 0.38, time 24.23s\n",
      "Saving best model\n",
      "epoch 5 : train loss 4.56081, train accuracy 1.34, val loss 4.61237, val accuracy 2.29, time 29.27s\n",
      "epoch 6 : train loss 4.55588, train accuracy 1.34, val loss 4.61262, val accuracy 1.91, time 25.21s\n",
      "epoch 7 : train loss 4.55413, train accuracy 1.43, val loss 4.61338, val accuracy 1.91, time 25.74s\n",
      "epoch 8 : train loss 4.55381, train accuracy 1.05, val loss 4.61193, val accuracy 1.53, time 20.11s\n",
      "epoch 9 : train loss 4.55460, train accuracy 1.81, val loss 4.61300, val accuracy 1.15, time 27.44s\n",
      "Saving best model\n",
      "epoch 10 : train loss 4.55594, train accuracy 1.62, val loss 4.61310, val accuracy 2.29, time 24.75s\n",
      "epoch 11 : train loss 4.54707, train accuracy 2.01, val loss 4.61317, val accuracy 0.38, time 27.59s\n",
      "epoch 12 : train loss 4.55046, train accuracy 1.62, val loss 4.61219, val accuracy 0.38, time 23.92s\n",
      "epoch 13 : train loss 4.54484, train accuracy 1.81, val loss 4.61229, val accuracy 0.76, time 20.96s\n",
      "epoch 14 : train loss 4.54655, train accuracy 1.81, val loss 4.61102, val accuracy 0.76, time 31.14s\n",
      "epoch 15 : train loss 4.54273, train accuracy 1.15, val loss 4.61094, val accuracy 0.38, time 21.06s\n",
      "epoch 16 : train loss 4.54255, train accuracy 1.91, val loss 4.61088, val accuracy 1.15, time 29.79s\n",
      "epoch 17 : train loss 4.53247, train accuracy 2.01, val loss 4.61135, val accuracy 1.15, time 20.91s\n",
      "epoch 18 : train loss 4.52513, train accuracy 2.29, val loss 4.60913, val accuracy 0.38, time 21.13s\n",
      "epoch 19 : train loss 4.52392, train accuracy 1.34, val loss 4.60854, val accuracy 1.53, time 31.02s\n",
      "epoch 20 : train loss 4.52431, train accuracy 2.01, val loss 4.60750, val accuracy 1.15, time 20.58s\n",
      "epoch 21 : train loss 4.51946, train accuracy 2.29, val loss 4.60888, val accuracy 0.76, time 30.32s\n",
      "epoch 22 : train loss 4.52116, train accuracy 2.39, val loss 4.61153, val accuracy 1.53, time 20.67s\n",
      "epoch 23 : train loss 4.50952, train accuracy 1.53, val loss 4.60910, val accuracy 1.53, time 21.81s\n",
      "epoch 24 : train loss 4.50544, train accuracy 2.87, val loss 4.61344, val accuracy 1.53, time 30.98s\n",
      "Saving best model\n",
      "epoch 25 : train loss 4.50657, train accuracy 1.81, val loss 4.60530, val accuracy 2.29, time 22.93s\n",
      "epoch 26 : train loss 4.49048, train accuracy 2.10, val loss 4.61174, val accuracy 1.15, time 29.31s\n",
      "Saving best model\n",
      "epoch 27 : train loss 4.48813, train accuracy 2.96, val loss 4.61065, val accuracy 2.29, time 20.45s\n",
      "epoch 28 : train loss 4.47683, train accuracy 2.29, val loss 4.61337, val accuracy 1.15, time 25.94s\n",
      "epoch 29 : train loss 4.48706, train accuracy 2.77, val loss 4.61780, val accuracy 1.15, time 26.50s\n",
      "Saving best model\n",
      "epoch 30 : train loss 4.46355, train accuracy 2.29, val loss 4.61552, val accuracy 2.29, time 25.91s\n",
      "Saving best model\n",
      "epoch 31 : train loss 4.47634, train accuracy 2.87, val loss 4.62116, val accuracy 3.05, time 25.81s\n",
      "epoch 32 : train loss 4.45744, train accuracy 3.06, val loss 4.61546, val accuracy 1.91, time 20.18s\n",
      "epoch 33 : train loss 4.45932, train accuracy 3.25, val loss 4.61504, val accuracy 1.53, time 32.39s\n",
      "epoch 34 : train loss 4.47347, train accuracy 2.96, val loss 4.61776, val accuracy 1.53, time 21.40s\n",
      "epoch 35 : train loss 4.46603, train accuracy 3.34, val loss 4.61721, val accuracy 0.76, time 29.61s\n",
      "epoch 36 : train loss 4.44697, train accuracy 3.53, val loss 4.62016, val accuracy 1.91, time 21.76s\n",
      "epoch 37 : train loss 4.45316, train accuracy 3.15, val loss 4.62339, val accuracy 1.15, time 20.36s\n",
      "epoch 38 : train loss 4.44364, train accuracy 2.96, val loss 4.61277, val accuracy 2.29, time 31.59s\n",
      "epoch 39 : train loss 4.45826, train accuracy 2.87, val loss 4.61713, val accuracy 1.53, time 20.35s\n",
      "epoch 40 : train loss 4.42293, train accuracy 3.44, val loss 4.62123, val accuracy 1.53, time 30.76s\n",
      "epoch 41 : train loss 4.45674, train accuracy 2.77, val loss 4.63211, val accuracy 1.53, time 20.05s\n",
      "epoch 42 : train loss 4.43639, train accuracy 2.58, val loss 4.62012, val accuracy 1.91, time 20.81s\n",
      "epoch 43 : train loss 4.43794, train accuracy 2.96, val loss 4.62347, val accuracy 1.91, time 31.85s\n",
      "Saving best model\n",
      "epoch 44 : train loss 4.42476, train accuracy 3.15, val loss 4.62765, val accuracy 3.05, time 20.18s\n",
      "Saving best model\n",
      "epoch 45 : train loss 4.43921, train accuracy 2.48, val loss 4.62849, val accuracy 3.44, time 30.71s\n",
      "epoch 46 : train loss 4.42525, train accuracy 3.25, val loss 4.63283, val accuracy 1.15, time 20.18s\n",
      "epoch 47 : train loss 4.43798, train accuracy 3.15, val loss 4.63276, val accuracy 1.91, time 20.57s\n",
      "epoch 48 : train loss 4.40330, train accuracy 4.01, val loss 4.64381, val accuracy 2.29, time 30.93s\n",
      "epoch 49 : train loss 4.42221, train accuracy 3.44, val loss 4.64292, val accuracy 1.91, time 20.43s\n",
      "epoch 50 : train loss 4.43412, train accuracy 3.72, val loss 4.65087, val accuracy 1.53, time 30.20s\n",
      "epoch 51 : train loss 4.42371, train accuracy 3.53, val loss 4.64865, val accuracy 1.91, time 20.97s\n",
      "epoch 52 : train loss 4.42431, train accuracy 3.44, val loss 4.65693, val accuracy 1.91, time 23.42s\n",
      "epoch 53 : train loss 4.42539, train accuracy 3.25, val loss 4.63046, val accuracy 2.29, time 29.17s\n",
      "epoch 54 : train loss 4.40447, train accuracy 3.34, val loss 4.65066, val accuracy 1.91, time 23.71s\n",
      "epoch 55 : train loss 4.42726, train accuracy 3.53, val loss 4.66180, val accuracy 1.15, time 28.13s\n",
      "epoch 56 : train loss 4.42584, train accuracy 2.96, val loss 4.65234, val accuracy 2.29, time 20.64s\n",
      "epoch 57 : train loss 4.40489, train accuracy 3.72, val loss 4.65031, val accuracy 2.67, time 28.54s\n",
      "epoch 58 : train loss 4.40353, train accuracy 2.96, val loss 4.65078, val accuracy 1.15, time 24.38s\n",
      "epoch 59 : train loss 4.41946, train accuracy 2.96, val loss 4.64249, val accuracy 2.29, time 27.02s\n",
      "epoch 60 : train loss 4.40513, train accuracy 4.11, val loss 4.64780, val accuracy 2.29, time 24.50s\n",
      "epoch 61 : train loss 4.41535, train accuracy 3.44, val loss 4.64787, val accuracy 2.29, time 20.55s\n",
      "epoch 62 : train loss 4.41440, train accuracy 2.67, val loss 4.65165, val accuracy 2.29, time 31.81s\n",
      "epoch 63 : train loss 4.41740, train accuracy 4.20, val loss 4.65189, val accuracy 1.15, time 20.03s\n",
      "epoch 64 : train loss 4.39133, train accuracy 3.72, val loss 4.63461, val accuracy 2.67, time 30.03s\n",
      "epoch 65 : train loss 4.41223, train accuracy 4.11, val loss 4.63742, val accuracy 1.53, time 20.89s\n",
      "epoch 66 : train loss 4.40049, train accuracy 3.72, val loss 4.66038, val accuracy 1.91, time 20.88s\n",
      "epoch 67 : train loss 4.41127, train accuracy 3.53, val loss 4.65855, val accuracy 2.29, time 31.38s\n",
      "epoch 68 : train loss 4.38535, train accuracy 3.82, val loss 4.64993, val accuracy 1.91, time 19.90s\n",
      "epoch 69 : train loss 4.41036, train accuracy 4.39, val loss 4.66595, val accuracy 0.76, time 30.65s\n",
      "epoch 70 : train loss 4.40615, train accuracy 3.82, val loss 4.66112, val accuracy 1.15, time 21.35s\n",
      "epoch 71 : train loss 4.39537, train accuracy 3.15, val loss 4.66043, val accuracy 1.53, time 20.78s\n",
      "epoch 72 : train loss 4.39487, train accuracy 3.15, val loss 4.67337, val accuracy 1.53, time 32.23s\n",
      "epoch 73 : train loss 4.38899, train accuracy 3.63, val loss 4.63458, val accuracy 1.53, time 20.73s\n",
      "epoch 74 : train loss 4.39903, train accuracy 3.72, val loss 4.66449, val accuracy 0.76, time 30.04s\n",
      "epoch 75 : train loss 4.39601, train accuracy 3.82, val loss 4.67798, val accuracy 1.53, time 21.43s\n",
      "epoch 76 : train loss 4.40657, train accuracy 2.96, val loss 4.66559, val accuracy 1.15, time 23.43s\n",
      "epoch 77 : train loss 4.39219, train accuracy 2.77, val loss 4.65404, val accuracy 2.67, time 28.15s\n",
      "epoch 78 : train loss 4.40925, train accuracy 3.15, val loss 4.65210, val accuracy 1.91, time 23.13s\n",
      "epoch 79 : train loss 4.37671, train accuracy 3.34, val loss 4.67522, val accuracy 1.91, time 27.70s\n",
      "epoch 80 : train loss 4.39596, train accuracy 3.72, val loss 4.67074, val accuracy 0.76, time 20.33s\n",
      "epoch 81 : train loss 4.39581, train accuracy 3.92, val loss 4.69967, val accuracy 1.15, time 26.95s\n",
      "Saving best model\n",
      "epoch 82 : train loss 4.37325, train accuracy 3.44, val loss 4.66543, val accuracy 3.44, time 25.73s\n",
      "epoch 83 : train loss 4.38716, train accuracy 3.63, val loss 4.68293, val accuracy 0.76, time 26.81s\n",
      "epoch 84 : train loss 4.40917, train accuracy 3.53, val loss 4.68278, val accuracy 1.91, time 24.14s\n",
      "epoch 85 : train loss 4.39229, train accuracy 3.63, val loss 4.67658, val accuracy 1.91, time 21.85s\n",
      "epoch 86 : train loss 4.38417, train accuracy 3.25, val loss 4.68173, val accuracy 1.53, time 30.28s\n",
      "epoch 87 : train loss 4.36550, train accuracy 4.01, val loss 4.66754, val accuracy 1.91, time 21.09s\n",
      "epoch 88 : train loss 4.39284, train accuracy 2.48, val loss 4.65303, val accuracy 1.53, time 30.22s\n",
      "epoch 89 : train loss 4.38180, train accuracy 4.20, val loss 4.69223, val accuracy 0.38, time 20.41s\n",
      "epoch 90 : train loss 4.36996, train accuracy 4.30, val loss 4.68994, val accuracy 0.76, time 21.81s\n",
      "epoch 91 : train loss 4.40225, train accuracy 2.87, val loss 4.68005, val accuracy 2.29, time 31.44s\n",
      "epoch 92 : train loss 4.36511, train accuracy 4.78, val loss 4.67875, val accuracy 1.15, time 20.61s\n",
      "epoch 93 : train loss 4.36763, train accuracy 3.63, val loss 4.67854, val accuracy 0.76, time 30.31s\n",
      "epoch 94 : train loss 4.37951, train accuracy 3.82, val loss 4.68537, val accuracy 1.15, time 20.42s\n",
      "epoch 95 : train loss 4.36916, train accuracy 4.20, val loss 4.68712, val accuracy 2.29, time 21.78s\n",
      "epoch 96 : train loss 4.37447, train accuracy 4.20, val loss 4.68526, val accuracy 1.15, time 31.14s\n",
      "epoch 97 : train loss 4.39983, train accuracy 4.01, val loss 4.68513, val accuracy 1.53, time 21.44s\n",
      "epoch 98 : train loss 4.39324, train accuracy 4.11, val loss 4.70048, val accuracy 1.15, time 29.80s\n",
      "epoch 99 : train loss 4.39441, train accuracy 3.72, val loss 4.66539, val accuracy 0.76, time 20.20s\n",
      "epoch 100 : train loss 4.37424, train accuracy 4.49, val loss 4.68890, val accuracy 1.53, time 23.90s\n",
      "epoch 101 : train loss 4.38260, train accuracy 4.87, val loss 4.68832, val accuracy 1.15, time 28.36s\n",
      "epoch 102 : train loss 4.38965, train accuracy 3.63, val loss 4.66937, val accuracy 0.38, time 23.99s\n",
      "epoch 103 : train loss 4.38343, train accuracy 3.92, val loss 4.66922, val accuracy 0.76, time 28.25s\n",
      "epoch 104 : train loss 4.37292, train accuracy 4.30, val loss 4.67632, val accuracy 1.53, time 20.04s\n",
      "epoch 105 : train loss 4.36927, train accuracy 3.82, val loss 4.70267, val accuracy 1.15, time 29.26s\n",
      "epoch 106 : train loss 4.36185, train accuracy 3.25, val loss 4.67788, val accuracy 1.15, time 23.66s\n",
      "epoch 107 : train loss 4.36844, train accuracy 3.72, val loss 4.67120, val accuracy 1.53, time 26.84s\n",
      "epoch 108 : train loss 4.36349, train accuracy 4.49, val loss 4.69501, val accuracy 1.91, time 24.15s\n",
      "epoch 109 : train loss 4.38241, train accuracy 4.30, val loss 4.69501, val accuracy 1.91, time 21.10s\n",
      "epoch 110 : train loss 4.36747, train accuracy 3.53, val loss 4.68374, val accuracy 1.15, time 30.49s\n",
      "epoch 111 : train loss 4.36254, train accuracy 3.44, val loss 4.67250, val accuracy 1.53, time 21.06s\n",
      "epoch 112 : train loss 4.35593, train accuracy 3.92, val loss 4.69113, val accuracy 0.76, time 31.35s\n",
      "epoch 113 : train loss 4.38240, train accuracy 3.53, val loss 4.70569, val accuracy 0.76, time 20.36s\n",
      "epoch 114 : train loss 4.37492, train accuracy 3.63, val loss 4.68242, val accuracy 1.15, time 20.72s\n",
      "epoch 115 : train loss 4.38081, train accuracy 3.34, val loss 4.70817, val accuracy 1.15, time 31.68s\n",
      "epoch 116 : train loss 4.36574, train accuracy 3.44, val loss 4.68878, val accuracy 1.15, time 20.45s\n",
      "epoch 117 : train loss 4.37298, train accuracy 3.63, val loss 4.68610, val accuracy 1.15, time 31.08s\n",
      "epoch 118 : train loss 4.36497, train accuracy 4.49, val loss 4.68398, val accuracy 0.76, time 20.62s\n",
      "epoch 119 : train loss 4.37533, train accuracy 4.01, val loss 4.69684, val accuracy 0.76, time 20.35s\n",
      "epoch 120 : train loss 4.38420, train accuracy 4.11, val loss 4.69108, val accuracy 1.91, time 31.61s\n",
      "epoch 121 : train loss 4.35052, train accuracy 4.49, val loss 4.68495, val accuracy 1.53, time 20.84s\n",
      "epoch 122 : train loss 4.35055, train accuracy 4.01, val loss 4.68730, val accuracy 0.76, time 31.30s\n",
      "epoch 123 : train loss 4.35408, train accuracy 3.63, val loss 4.70778, val accuracy 0.76, time 20.51s\n",
      "epoch 124 : train loss 4.36760, train accuracy 4.87, val loss 4.70321, val accuracy 1.91, time 23.58s\n",
      "Saving best model\n",
      "epoch 125 : train loss 4.35079, train accuracy 4.20, val loss 4.70645, val accuracy 3.44, time 28.62s\n",
      "epoch 126 : train loss 4.36626, train accuracy 3.63, val loss 4.70412, val accuracy 0.76, time 23.16s\n",
      "epoch 127 : train loss 4.37442, train accuracy 3.92, val loss 4.69345, val accuracy 2.29, time 27.92s\n",
      "epoch 128 : train loss 4.34441, train accuracy 4.01, val loss 4.67717, val accuracy 1.15, time 20.46s\n",
      "epoch 129 : train loss 4.37871, train accuracy 3.82, val loss 4.70375, val accuracy 0.38, time 27.73s\n",
      "epoch 130 : train loss 4.35906, train accuracy 3.72, val loss 4.68575, val accuracy 1.53, time 24.99s\n",
      "epoch 131 : train loss 4.34493, train accuracy 4.11, val loss 4.69886, val accuracy 1.15, time 27.13s\n",
      "epoch 132 : train loss 4.35803, train accuracy 4.20, val loss 4.67549, val accuracy 1.53, time 24.64s\n",
      "epoch 133 : train loss 4.36719, train accuracy 3.25, val loss 4.72637, val accuracy 1.53, time 20.56s\n",
      "epoch 134 : train loss 4.34295, train accuracy 4.20, val loss 4.68525, val accuracy 1.91, time 30.81s\n",
      "epoch 135 : train loss 4.35171, train accuracy 3.63, val loss 4.69545, val accuracy 1.15, time 20.93s\n",
      "epoch 136 : train loss 4.36644, train accuracy 4.01, val loss 4.69666, val accuracy 0.38, time 30.63s\n",
      "epoch 137 : train loss 4.36289, train accuracy 4.20, val loss 4.72052, val accuracy 0.76, time 19.92s\n",
      "epoch 138 : train loss 4.35263, train accuracy 3.72, val loss 4.69082, val accuracy 2.29, time 21.70s\n",
      "epoch 139 : train loss 4.35618, train accuracy 4.11, val loss 4.72803, val accuracy 1.53, time 30.89s\n",
      "epoch 140 : train loss 4.36647, train accuracy 3.82, val loss 4.69715, val accuracy 0.76, time 21.79s\n",
      "epoch 141 : train loss 4.33520, train accuracy 4.20, val loss 4.69434, val accuracy 0.38, time 29.57s\n",
      "epoch 142 : train loss 4.34001, train accuracy 2.96, val loss 4.70462, val accuracy 2.67, time 20.55s\n",
      "epoch 143 : train loss 4.34163, train accuracy 4.49, val loss 4.69728, val accuracy 1.53, time 21.80s\n",
      "epoch 144 : train loss 4.35022, train accuracy 3.44, val loss 4.69806, val accuracy 0.38, time 31.20s\n",
      "epoch 145 : train loss 4.34462, train accuracy 4.01, val loss 4.70329, val accuracy 1.15, time 21.68s\n",
      "epoch 146 : train loss 4.32539, train accuracy 4.49, val loss 4.69829, val accuracy 1.15, time 29.28s\n",
      "epoch 147 : train loss 4.35416, train accuracy 4.30, val loss 4.71595, val accuracy 0.00, time 17.42s\n",
      "epoch 148 : train loss 4.36205, train accuracy 4.11, val loss 4.71757, val accuracy 1.15, time 17.65s\n",
      "epoch 149 : train loss 4.34398, train accuracy 4.01, val loss 4.69783, val accuracy 0.00, time 18.75s\n",
      "epoch 150 : train loss 4.33497, train accuracy 4.30, val loss 4.71066, val accuracy 1.15, time 17.24s\n",
      "epoch 151 : train loss 4.34483, train accuracy 4.01, val loss 4.68874, val accuracy 1.53, time 17.76s\n",
      "epoch 152 : train loss 4.35533, train accuracy 4.49, val loss 4.71117, val accuracy 1.53, time 18.33s\n",
      "epoch 153 : train loss 4.32533, train accuracy 4.58, val loss 4.69672, val accuracy 1.15, time 17.28s\n",
      "epoch 154 : train loss 4.33475, train accuracy 4.49, val loss 4.70383, val accuracy 1.15, time 17.51s\n",
      "epoch 155 : train loss 4.36487, train accuracy 4.58, val loss 4.71154, val accuracy 2.29, time 17.41s\n",
      "epoch 156 : train loss 4.33213, train accuracy 3.25, val loss 4.70674, val accuracy 0.38, time 18.83s\n",
      "epoch 157 : train loss 4.35799, train accuracy 3.25, val loss 4.72213, val accuracy 0.76, time 17.26s\n",
      "epoch 158 : train loss 4.32672, train accuracy 4.58, val loss 4.70469, val accuracy 1.53, time 17.83s\n",
      "epoch 159 : train loss 4.32233, train accuracy 4.58, val loss 4.71886, val accuracy 0.38, time 17.58s\n",
      "epoch 160 : train loss 4.32663, train accuracy 3.72, val loss 4.70478, val accuracy 1.53, time 17.56s\n",
      "epoch 161 : train loss 4.31208, train accuracy 5.06, val loss 4.70576, val accuracy 1.15, time 17.57s\n",
      "epoch 162 : train loss 4.33441, train accuracy 3.72, val loss 4.73558, val accuracy 1.15, time 17.43s\n",
      "epoch 163 : train loss 4.32240, train accuracy 4.01, val loss 4.71321, val accuracy 0.38, time 18.54s\n",
      "epoch 164 : train loss 4.34973, train accuracy 3.63, val loss 4.71102, val accuracy 0.76, time 17.20s\n",
      "epoch 165 : train loss 4.34094, train accuracy 4.20, val loss 4.69094, val accuracy 1.53, time 17.38s\n",
      "epoch 166 : train loss 4.33007, train accuracy 4.58, val loss 4.70519, val accuracy 1.15, time 17.44s\n",
      "epoch 167 : train loss 4.32913, train accuracy 3.25, val loss 4.68351, val accuracy 1.15, time 17.60s\n",
      "epoch 168 : train loss 4.33518, train accuracy 4.20, val loss 4.71073, val accuracy 1.15, time 17.41s\n",
      "Saving best model\n",
      "epoch 169 : train loss 4.31114, train accuracy 4.87, val loss 4.70302, val accuracy 3.44, time 18.39s\n",
      "epoch 170 : train loss 4.32365, train accuracy 4.97, val loss 4.73434, val accuracy 0.00, time 17.95s\n",
      "epoch 171 : train loss 4.34151, train accuracy 4.01, val loss 4.71860, val accuracy 0.76, time 17.20s\n",
      "epoch 172 : train loss 4.32564, train accuracy 3.92, val loss 4.70350, val accuracy 0.38, time 17.56s\n",
      "epoch 173 : train loss 4.29168, train accuracy 4.11, val loss 4.70261, val accuracy 1.53, time 17.28s\n",
      "epoch 174 : train loss 4.32737, train accuracy 5.25, val loss 4.70247, val accuracy 1.53, time 17.07s\n",
      "epoch 175 : train loss 4.31081, train accuracy 4.68, val loss 4.69269, val accuracy 1.15, time 17.43s\n",
      "epoch 176 : train loss 4.29389, train accuracy 4.30, val loss 4.70944, val accuracy 0.38, time 19.24s\n",
      "epoch 177 : train loss 4.30242, train accuracy 4.97, val loss 4.70177, val accuracy 1.53, time 17.38s\n",
      "epoch 178 : train loss 4.31605, train accuracy 5.16, val loss 4.69655, val accuracy 1.15, time 17.39s\n",
      "epoch 179 : train loss 4.31518, train accuracy 3.92, val loss 4.68185, val accuracy 2.29, time 17.34s\n",
      "epoch 180 : train loss 4.30130, train accuracy 4.58, val loss 4.74347, val accuracy 0.76, time 17.52s\n",
      "epoch 181 : train loss 4.30176, train accuracy 3.82, val loss 4.70499, val accuracy 1.15, time 16.80s\n",
      "epoch 182 : train loss 4.30342, train accuracy 4.30, val loss 4.69945, val accuracy 1.15, time 17.00s\n",
      "epoch 183 : train loss 4.29984, train accuracy 5.06, val loss 4.70574, val accuracy 2.29, time 19.40s\n",
      "epoch 184 : train loss 4.30758, train accuracy 5.06, val loss 4.72562, val accuracy 0.76, time 17.72s\n",
      "epoch 185 : train loss 4.32324, train accuracy 4.30, val loss 4.71279, val accuracy 0.76, time 16.96s\n",
      "epoch 186 : train loss 4.30378, train accuracy 5.25, val loss 4.69988, val accuracy 1.15, time 17.48s\n",
      "epoch 187 : train loss 4.28692, train accuracy 5.44, val loss 4.70559, val accuracy 0.38, time 17.64s\n",
      "epoch 188 : train loss 4.31581, train accuracy 5.16, val loss 4.69734, val accuracy 0.38, time 17.34s\n",
      "epoch 189 : train loss 4.30966, train accuracy 4.58, val loss 4.68842, val accuracy 0.76, time 17.97s\n",
      "epoch 190 : train loss 4.29030, train accuracy 5.35, val loss 4.70714, val accuracy 1.15, time 19.70s\n",
      "epoch 191 : train loss 4.31621, train accuracy 4.20, val loss 4.72193, val accuracy 1.15, time 17.57s\n",
      "epoch 192 : train loss 4.29679, train accuracy 4.49, val loss 4.69869, val accuracy 1.53, time 17.51s\n",
      "epoch 193 : train loss 4.28827, train accuracy 3.44, val loss 4.69565, val accuracy 1.15, time 17.59s\n",
      "epoch 194 : train loss 4.28093, train accuracy 4.78, val loss 4.70285, val accuracy 0.76, time 17.57s\n",
      "epoch 195 : train loss 4.28405, train accuracy 5.16, val loss 4.70354, val accuracy 0.38, time 17.42s\n",
      "epoch 196 : train loss 4.26599, train accuracy 5.35, val loss 4.71246, val accuracy 1.53, time 17.87s\n",
      "epoch 197 : train loss 4.30359, train accuracy 3.92, val loss 4.70922, val accuracy 0.38, time 18.59s\n",
      "epoch 198 : train loss 4.30350, train accuracy 4.87, val loss 4.69219, val accuracy 0.38, time 17.37s\n",
      "epoch 199 : train loss 4.28816, train accuracy 4.78, val loss 4.68821, val accuracy 0.38, time 17.69s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import *\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=.2, shuffle=True, random_state=13)\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        c = torchvision.transforms.Compose([Grayscale(),\n",
    "                                            RandomHorizontalFlip(),\n",
    "                                            RandomPerspective(),\n",
    "                                            RandomRotation(degrees=(0, 180)),\n",
    "                                            RandomVerticalFlip(),\n",
    "                                            Resize((96,96)),\n",
    "                                            functional.to_tensor])\n",
    "        return (\n",
    "            c(Image.open(\"../datasets/datasets_train/train/\"+row[\"im_name\"])),\n",
    "            row[\"model_e\"],\n",
    "        )\n",
    "\n",
    "train_set = MyDataset(df_train)\n",
    "val_set = MyDataset(df_test)\n",
    "\n",
    "#train_size = int(0.8 * len(dataset))\n",
    "#test_size = len(dataset) - train_size\n",
    "\n",
    "#train_set, val_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=val_set, batch_size=batch_size)\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 3, 3, padding='same')\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = torch.nn.Conv2d(3, 6, 3, padding='same')\n",
    "        self.conv3 = torch.nn.Conv2d(6, 12, 3, padding='same')\n",
    "        self.fc = torch.nn.Linear(1728, n_classes)\n",
    "        self.dropout = torch.nn.Dropout()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,1,96,96)\n",
    "        x = self.dropout(self.pool(F.relu(self.conv1(x))))\n",
    "        x = self.dropout(self.pool(F.relu(self.conv2(x))))\n",
    "        x = self.dropout(self.pool(F.relu(self.conv3(x))))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "my_model = ConvNet()\n",
    "\n",
    "optimizer = torch.optim.Adam(my_model.parameters(), lr=3e-4)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.5e-1)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "loss_l_train = []\n",
    "loss_l_val = []\n",
    "nb_epoch = 200\n",
    "\n",
    "loss_l_train = []\n",
    "loss_l_val = []\n",
    "acc_train = []\n",
    "acc_val = []\n",
    "for num_epoch in range(nb_epoch):\n",
    "    t0 = time.time()\n",
    "    my_model.train()\n",
    "    running_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        outputs = my_model(inputs) # Forward pass: Compute predicted y by passing  x to the model          \n",
    "        labels = labels\n",
    "        loss = criterion(outputs,labels) # Compute loss \n",
    "\n",
    "        optimizer.zero_grad() # re-init the gradients (otherwise they are cumulated)\n",
    "        loss.backward() # perform back-propagation\n",
    "        optimizer.step() # update the weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        y_pred_softmax = torch.log_softmax(outputs, dim = 1)\n",
    "        _, predicted = torch.max(y_pred_softmax, dim = 1) \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    loss_l_train.append(running_loss/(i+1))\n",
    "    acc_train.append(correct*100/total)\n",
    "\n",
    "    my_model.eval()\n",
    "    running_loss_val = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(test_loader):\n",
    "            outputs = my_model(inputs)  \n",
    "            labels = labels\n",
    "            loss = criterion(outputs,labels)\n",
    "\n",
    "            running_loss_val += loss.item()\n",
    "            \n",
    "            y_pred_softmax = torch.log_softmax(outputs, dim = 1)\n",
    "            _, predicted = torch.max(y_pred_softmax, dim = 1) \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "    acc_val.append(correct*100/total)\n",
    "    loss_l_val.append(running_loss_val/(i+1))\n",
    "\n",
    "    if acc_val[-1] == max(acc_val):\n",
    "        print(\"Saving best model\")\n",
    "        torch.save(my_model, 'models/best-classifier.pt')\n",
    "        torch.save(my_model.state_dict(), 'models/best-classifier-parameters.pt')\n",
    "\n",
    "    print(f'epoch {num_epoch} : train loss {loss_l_train[-1]:.5f}, train accuracy {acc_train[-1]:.2f}, val loss {loss_l_val[-1]:.5f}, val accuracy {acc_val[-1]:.2f}, time {time.time()-t0:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bae116-6b86-468e-8f2c-f475ec0e138e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
