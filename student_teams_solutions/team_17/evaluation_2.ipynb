{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a3afe-e905-4753-b95e-c1a245e10346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/activities_data/hi__paris_2022_hackathon/final_challenge/group_00099_shared_workspace'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4328be74-f4bf-44a1-8d3b-f61331578d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-3-6 torch 1.10.0+cu113 CUDA:0 (Tesla V100S-PCIE-32GB, 32510MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import glob\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a781f348-2d6a-4e90-bdd6-23509412b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "model_emissions = load_model('/home/jovyan/activities_data/hi__paris_2022_hackathon/final_challenge/group_00099_shared_workspace/models/model_pred_emission.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a16433e6-c620-4151-be74-3e52da18359d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161.6751614"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_size = (188,256,3)\n",
    "im_path = glob.glob(\"../datasets/datasets_test/test/*\")[0]\n",
    "image = Image.open(im_path)\n",
    "im = np.asanyarray(image)\n",
    "im = cv2.resize(im, dsize=target_size[:2], interpolation=cv2.INTER_CUBIC)\n",
    "plt.imshow(im)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "im.shape\n",
    "\n",
    "def make_prediction(model, im):\n",
    "    classes_emissions = np.array([[129.76678445],\n",
    "       [161.6751614 ],\n",
    "       [199.10837695],\n",
    "       [335.06065575]]).ravel()\n",
    "    \n",
    "    mean_emission = 201.73246813265277\n",
    "    pred = model.predict(im)\n",
    "    \n",
    "    pred_emission = np.array([classes_emissions[i] for i in np.argmax(pred, axis =1)]).ravel()\n",
    "\n",
    "    # pred_emission_ponderees = (pred_emission@classes_emissions).ravel() ##* 150/pred_emission.mean()\n",
    "    # pred_emission_rescalees = pred_emission * mean_emission/pred_emission_ponderees.mean()\n",
    "    \n",
    "    return pred_emission[0]\n",
    "\n",
    "# Test on one sample\n",
    "make_prediction(model_emissions, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d974de8-3da1-4c3f-93e7-d2be4c79c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = True\n",
    "\n",
    "df = pd.DataFrame(columns = [\"im_name\",\"x_min\",\"y_min\",\"x_max\",\"y_max\", \"e\"])\n",
    "for i, img in enumerate(glob.glob(\"../datasets/datasets_test/test/*\")):\n",
    "    row = [img.split(\"/\")[-1]]\n",
    "    im = np.asanyarray(Image.open(img).convert('RGB'))\n",
    "    predictions = model(im).pandas().xyxy[0]\n",
    "    predictions = predictions[((predictions[\"name\"]==\"car\") | (predictions[\"name\"]==\"truck\"))]\n",
    "    try:\n",
    "        running_box = predictions.loc[((predictions[\"xmax\"]-predictions[\"xmin\"]) * (predictions[\"ymax\"] - predictions[\"ymin\"])).argmax(), \n",
    "                               [\"xmin\",\"ymin\",\"xmax\",\"ymax\"]].tolist()\n",
    "        if crop:\n",
    "            im_toPredict = np.asanyarray(Image.fromarray(im).crop([running_box[0],running_box[1],running_box[2],running_box[3]]))\n",
    "            # print(im_toPredict.shape)\n",
    "            im_toPredict = cv2.resize(im_toPredict, dsize=(256,188), interpolation=cv2.INTER_CUBIC)\n",
    "            im_toPredict = np.expand_dims(im_toPredict.reshape((256,188,3)), axis=0)\n",
    "            # pred_e.append(model_emissions.predict(im_toPredict))\n",
    "            e = make_prediction(model_emissions, im_toPredict)\n",
    "    except:\n",
    "        running_box = [0,0,0,0]\n",
    "        if crop:\n",
    "            e = 0\n",
    "    \n",
    "    if crop == False:\n",
    "        im_toPredict = cv2.resize(im, dsize=(256,188), interpolation=cv2.INTER_CUBIC)\n",
    "        im_toPredict = np.expand_dims(im_toPredict.reshape((256,188,3)), axis=0)\n",
    "        # pred_e.append(model_emissions.predict(im_toPredict))\n",
    "        e = make_prediction(model_emissions, im_toPredict)\n",
    "        \n",
    "    row.extend(running_box)\n",
    "    row.append(e)\n",
    "    df.loc[i, :] = row\n",
    "    # print(i)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af125019-ba7d-4ca1-86f8-86e2b3ca37a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    \"/home/jovyan/activities_data/hi__paris_2022_hackathon/final_challenge/group_00099_shared_workspace/submissions/submission.csv\", index=False\n",
    ")  # xxxx for your Hfactory ID group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
