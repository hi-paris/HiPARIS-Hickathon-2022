{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d972b76-f735-48ec-8fde-bf56c5000560",
   "metadata": {},
   "source": [
    "T√©l√©com MS Group\n",
    "\n",
    "HI!CKATHON 2022  \n",
    "\n",
    "6/3/2022  \n",
    "\n",
    "# I.\tOVERVIEW\n",
    "## 1.\tProject Background and Description\n",
    " \tDescribe how this project came about, and the purpose.\n",
    "We are a team of 4 MS students learning about Big Data and AI this year at T√©l√©com Paris. We heard about this project directly from our school's teacher and we saw it as a great opportunity to tackle a challenging task. For all of us it was a first-timer participating in such a competition. \n",
    "\n",
    "## 2.\tProject Scope\n",
    " \t Scope answers questions including what will be done, what won‚Äôt be done, and what the result will look like.\n",
    "\n",
    "What won't be done :\n",
    "- \n",
    "\n",
    "## 3.\tPresentation of the group\n",
    " \tInclude your specialization at school, etc.\n",
    "\n",
    "| First name | Last name | Year of studies & Profile | School  | Skills       | Roles/Tasks | Observations |\n",
    "| ---------- | --------- | ------------------------- | ------  | ------       | ----------- | ------------ |\n",
    "| Phil√©as    | SAMIR     | MS Big Data - Psychologist| T√©l√©com | Python/ML/DL | Modeling    |       |\n",
    "| Pierrick   | LEROY     | MS AI                     | T√©l√©com | Python/ML/DL | Modeling    |              |\n",
    "| Laouaouda  | AMINE     | MS Big Data               | T√©l√©com | Python/ML/DL | EDA         |              |\n",
    "| Mejait     | ASMAE     | MS AI                     | T√©l√©com | Python/ML/DL | EDA         |              |\n",
    "\n",
    "\n",
    "\n",
    "## 4.\tTask Management\n",
    " \tDescribe how you interacted and collaborated as a team, and the effect of every member‚Äôs unique background on the project.\n",
    "We had various proficiency and expertise levels on the team as MS people at T√©l√©com all have different backgrounds. To collaborate efficiently we set up a few things, notably:\n",
    "- Common data exploration : to make sure everyone was on the same page we broadcasted\n",
    "\n",
    "Pierrick \n",
    "\n",
    "\n",
    "# II.\tPROJECT MANAGEMENT\n",
    "## 1.\tData Understanding\n",
    " \tProvided the initial collection of data has already occurred, this step includes identifying and defining the relevant data, exploring the range, scale, formats, contents, and biases of the data, and evaluating the quality and validity of the resulting data.\n",
    "We have over 2600 images with less than half that contain a car. For the images with cars, on average, each model is represented around 13 times. Some models have as few as 4 images. This means we actually have little data to train a model image classifier.\n",
    "\n",
    "## 2.\tData Pre-processing\n",
    " \tExplain how the selection of data was manipulated and modified to remove redundant features and improve the quality of the data. Describe the preprocessing techniques used, such as data augmentation.\n",
    "We tried to use information about the model to predict its emissions, such as the year or the model category (SUV, van, coup√©, etc.). This did not provide good enough results to be pursued further.\n",
    "Since we are working on images, preferred models are convolutional neural networks, also called ConvNets. These models, like all neural networks, can very easily overfit. To prevent such overfitting, we use data augmentation : we apply random transformations to images as they are passed to the network during training. This is a well-known technique that leads to better model generalization.\n",
    "\n",
    "## 3.\tModeling Development\n",
    " \tDescribe how you selected algorithms, how you calibrated them according to the data and how - in fine - you selected the best AI model using a well-defined set of metrics.\n",
    "Given the limited number of images per class, we chose to use two models stacked on top of eachother :\n",
    "- a model based on the YOLO architecture and weights (transfer learning), to decide whether there is a car in the image, and get its bounding box,\n",
    "- a regression model that predicts the car emissions from the YOLO-cropped image.\n",
    "\n",
    "## 4.\t Deployment Strategy\n",
    " \tWhat best practices/norms did you follow? How do you plan on deploying your IA solution?\n",
    "Enter your answer here.\n",
    "\n",
    "\n",
    "# III.\tCARBON FOOTPRINT LIMITATION\n",
    " \tDescribe the taken measures/actions during the development of your solution in view of limiting the carbon footprint.\n",
    "![Business_mdel](\"./Business_model.PNG\")\n",
    "\n",
    "\n",
    "# IV.\tCONCLUSION\n",
    " \tTell us about the actual results, their limitations as well as future perspectives and improvements.\n",
    "Enter your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4328be74-f4bf-44a1-8d3b-f61331578d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 üöÄ 2022-3-5 torch 1.10.0+cu113 CUDA:0 (Tesla V100S-PCIE-32GB, 32510MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import glob\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d974de8-3da1-4c3f-93e7-d2be4c79c179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>im_name</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85854523.jpg</td>\n",
       "      <td>191.033493</td>\n",
       "      <td>678.842102</td>\n",
       "      <td>1902.317993</td>\n",
       "      <td>1253.441528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16663988681.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19090334369.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71540198.jpg</td>\n",
       "      <td>70.247467</td>\n",
       "      <td>61.608627</td>\n",
       "      <td>1641.056152</td>\n",
       "      <td>809.442078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85427036.jpg</td>\n",
       "      <td>248.620361</td>\n",
       "      <td>197.806946</td>\n",
       "      <td>1038.264771</td>\n",
       "      <td>651.789429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>89862599.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.415718</td>\n",
       "      <td>989.538208</td>\n",
       "      <td>564.733154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>7055251597.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>3848520911.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>73537501.jpg</td>\n",
       "      <td>85.125076</td>\n",
       "      <td>81.848251</td>\n",
       "      <td>524.960022</td>\n",
       "      <td>368.802368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>98186923.jpg</td>\n",
       "      <td>164.834427</td>\n",
       "      <td>183.549835</td>\n",
       "      <td>744.949036</td>\n",
       "      <td>544.682434</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1024 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              im_name       x_min       y_min        x_max        y_max  e\n",
       "0        85854523.jpg  191.033493  678.842102  1902.317993  1253.441528  0\n",
       "1     16663988681.jpg           0           0            0            0  0\n",
       "2     19090334369.jpg           0           0            0            0  0\n",
       "3        71540198.jpg   70.247467   61.608627  1641.056152   809.442078  0\n",
       "4        85427036.jpg  248.620361  197.806946  1038.264771   651.789429  0\n",
       "...               ...         ...         ...          ...          ... ..\n",
       "1019     89862599.jpg         0.0   78.415718   989.538208   564.733154  0\n",
       "1020   7055251597.jpg           0           0            0            0  0\n",
       "1021   3848520911.jpg           0           0            0            0  0\n",
       "1022     73537501.jpg   85.125076   81.848251   524.960022   368.802368  0\n",
       "1023     98186923.jpg  164.834427  183.549835   744.949036   544.682434  0\n",
       "\n",
       "[1024 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop = False\n",
    "\n",
    "df = pd.DataFrame(columns = [\"im_name\",\"x_min\",\"y_min\",\"x_max\",\"y_max\", \"e\"])\n",
    "for i, img in enumerate(glob.glob(\"../datasets/datasets_test/test/*\")):\n",
    "    row = [img.split(\"/\")[-1]]\n",
    "    im = np.asanyarray(Image.open(img))\n",
    "    predictions = model(im).pandas().xyxy[0]\n",
    "    predictions = predictions[((predictions[\"name\"]==\"car\") | (predictions[\"name\"]==\"truck\"))]\n",
    "    try:\n",
    "        running_box = predictions.loc[((predictions[\"xmax\"]-predictions[\"xmin\"]) * (predictions[\"ymax\"] - predictions[\"ymin\"])).argmax(), \n",
    "                               [\"xmin\",\"ymin\",\"xmax\",\"ymax\"]].tolist()\n",
    "        if crop:\n",
    "            im_toPredict = im[running_box[1]:running_box[3],running_box[0]:running_box[2]]\n",
    "            im_toPredict = cv2.resize(im_toPredict, dsize=(256,188), interpolation=cv2.INTER_CUBIC).T\n",
    "            im_toPredict = np.expand_dims(im_toPredict, axis=0)\n",
    "            # pred_e.append(model_emissions.predict(im_toPredict))\n",
    "            e = make_prediction(model_emissions, im_toPredict)\n",
    "    except:\n",
    "        running_box = [0,0,0,0]\n",
    "        if crop:\n",
    "            e = 0\n",
    "    \n",
    "    if crop == False:\n",
    "        im_toPredict = cv2.resize(im_toPredict, dsize=(256,188), interpolation=cv2.INTER_CUBIC).T\n",
    "        im_toPredict = np.expand_dims(im_toPredict, axis=0)\n",
    "        # pred_e.append(model_emissions.predict(im_toPredict))\n",
    "        e = make_prediction(model_emissions, im_toPredict)\n",
    "        \n",
    "    row.extend(running_box)\n",
    "    row.append(e)\n",
    "    df.loc[i, :] = row\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29636c78-168a-4e6d-af7d-eb4dba3be6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "i=1\n",
    "for img_path in glob.glob(\"../datasets/datasets_test/test/*\")[:9]:\n",
    "    ax = fig.add_subplot(3,3,i)\n",
    "    im = np.asanyarray(Image.open(img_path))\n",
    "    predictions = model(im).pandas().xyxy[0]\n",
    "    predictions = predictions[((predictions[\"name\"]==\"car\") | (predictions[\"name\"]==\"truck\"))]# & (predictions[\"confidence\"]>=.6)]\n",
    "    \n",
    "    for pred in predictions.iterrows():\n",
    "        x1, y1, x2, y2 = pred[1][[\"xmin\",\"ymin\",\"xmax\",\"ymax\"]]\n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), x2 - x1, y2 - y1, linewidth=1, edgecolor=\"blue\", facecolor=\"none\",\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x1, y2+5, round(pred[1][\"confidence\"],2), va=\"top\", fontsize=18)\n",
    "    \n",
    "    ax.imshow(im)\n",
    "    ax.set_title(model_emissions.predict(im))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    i+=1\n",
    "\n",
    "plt.savefig(\"test_preds.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce86ee9b-5a06-4196-954c-859491b57d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
