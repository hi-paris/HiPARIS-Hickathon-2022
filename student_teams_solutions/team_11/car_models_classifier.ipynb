{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XlXkQ6qx_Xay"
   },
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import json\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! rm model_data/test/*/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!ls -l '/home/jovyan/activities_data/hi__paris_2022_hackathon/final_challenge/group_00093_shared_workspace/model_data/test/Acura ZDX Hatchback 2012'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! rm -r model_data/test/.ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYdee71UJDSF"
   },
   "source": [
    "# **Steps** <p>\n",
    "Step 1: Load Dataset <p>\n",
    "Step 2: Transform the Dataset <p>\n",
    "Step 3: Create Model <p>\n",
    "Step 4: Train Model <p>\n",
    "Step 5: Save the Model <p>\n",
    "Step 6: Load the Model <p>\n",
    "Step 7: Predict the Image <p>\n",
    "Step 8: Show the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4T7noSJhJUFr"
   },
   "source": [
    "## Step 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74CbnuuJAx4Y"
   },
   "outputs": [],
   "source": [
    "#data_dir = '/content/drive/My Drive/Colab Notebooks/carsdata/car_data/'\n",
    "\n",
    "train_dir = '/home/jovyan/activities_data/hi__paris_2022_hackathon/final_challenge/group_00093_shared_workspace/car_data/car_data/train'\n",
    "test_dir = '/home/jovyan/activities_data/hi__paris_2022_hackathon/final_challenge/group_00093_shared_workspace/car_data/car_data/test'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLysmbnmJemX"
   },
   "source": [
    "## Step 2: Transform the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOqT-9GXA8F_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training transform includes random rotation and flip to build a more robust model\n",
    "train_transforms = transforms.Compose([transforms.Resize((244,244)),\n",
    "                                       transforms.RandomRotation(30),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# The validation set will use the same transform as the test set\n",
    "test_transforms = transforms.Compose([transforms.Resize((244,244)),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "\n",
    "\n",
    "# Using the image datasets and the trainforms, define the dataloaders\n",
    "# The trainloader will have shuffle=True so that the order of the images do not affect the model\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "#validloader = torch.utils.data.DataLoader(valid_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 8144\n",
       "    Root location: /home/jovyan/activities_data/hi__paris_2022_hackathon/final_challenge/group_00093_shared_workspace/car_data/car_data/train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(244, 244), interpolation=bilinear, max_size=None, antialias=None)\n",
       "               RandomRotation(degrees=[-30.0, 30.0], interpolation=nearest, expand=False, fill=0)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M265WLOdJ3xV"
   },
   "source": [
    "## Step 3: Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1emIi-zkXNz1",
    "outputId": "2a93d3d5-0c02-42c9-b596-667df7cb2327"
   },
   "outputs": [],
   "source": [
    "#model = models.densenet121(pretrained=True)\n",
    "model = models.resnet34(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ZcqibDULVbil",
    "outputId": "a4ecd4de-6a83-4c43-b141-e63791e084a2"
   },
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 196)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZQGN3U1tWu0"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H1j802WQKhRa"
   },
   "source": [
    "## Step 4: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7OXITrCGu5J"
   },
   "outputs": [],
   "source": [
    "# Implement a function for the validation pass\n",
    "def validation(model, testloader, criterion):\n",
    "    valid_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # change model to work with cuda\n",
    "    model.to('cuda')\n",
    "\n",
    "    # Iterate over data from validloader\n",
    "    for ii, (images, labels) in enumerate(testloader):\n",
    "    \n",
    "        # Change images and labels to work with cuda\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "        # Forward pass image though model for prediction\n",
    "        output = model.forward(images)\n",
    "        # Calculate loss\n",
    "        valid_loss += criterion(output, labels).item()\n",
    "        # Calculate probability\n",
    "        ps = torch.exp(output)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return valid_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "eBpYU-KpuyFq",
    "outputId": "3f37ee6f-571b-4d84-9efa-9b88a9505692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. epochs: 1,             Training Loss: 5.16             test Loss: 4.598             test Accuracy: 0.065\n",
      "No. epochs: 2,             Training Loss: 1.455             test Loss: 3.446             test Accuracy: 0.209\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps = 0\n",
    "print_every = 40\n",
    "\n",
    "# change to gpu mode\n",
    "model.to('cuda')\n",
    "model.train()\n",
    "for e in range(epochs):\n",
    "\n",
    "    running_loss = 0\n",
    "    \n",
    "    # Iterating over data to carry out training step\n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "        steps += 1\n",
    "        \n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "        # zeroing parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward and backward passes\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Carrying out validation step\n",
    "        if steps % print_every == 0:\n",
    "            # setting model to evaluation mode during validation\n",
    "            model.eval()\n",
    "            \n",
    "            # Gradients are turned off as no longer in training\n",
    "            with torch.no_grad():\n",
    "                test_loss, accuracy = validation(model, testloader, criterion)\n",
    "            \n",
    "            print(f\"No. epochs: {e+1}, \\\n",
    "            Training Loss: {round(running_loss/print_every,3)} \\\n",
    "            test Loss: {round(test_loss/len(testloader),3)} \\\n",
    "            test Accuracy: {round(float(accuracy/len(testloader)),3)}\")\n",
    "            \n",
    "            \n",
    "            # Turning training back on\n",
    "            model.train()\n",
    "            lrscheduler.step(accuracy * 100)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cXyFWRKJIaqU",
    "outputId": "9c721d83-bc50-4a6d-bbc1-5cc8d5fc8c5d"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.to('cuda')\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        # Get probabilities\n",
    "        outputs = model(images)\n",
    "        # Turn probabilities into predictions\n",
    "        _, predicted_outcome = torch.max(outputs.data, 1)\n",
    "        # Total number of images\n",
    "        total += labels.size(0)\n",
    "        # Count number of cases in which predictions are correct\n",
    "        correct += (predicted_outcome == labels).sum().item()\n",
    "\n",
    "print(f\"Test accuracy of model: {round(100 * correct / total,3)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dekV68M3Kufx"
   },
   "source": [
    "## Step 5: Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5vcTL2RZBdDk"
   },
   "outputs": [],
   "source": [
    "# Saving: feature weights, new model.fc, index-to-class mapping, optimiser state, and No. of epochs\n",
    "checkpoint = {'state_dict': model.state_dict(),\n",
    "              'model': model.fc,\n",
    "              'class_to_idx': train_data.class_to_idx,\n",
    "              'opt_state': optimizer.state_dict,\n",
    "              'num_epochs': epochs}\n",
    "\n",
    "torch.save(checkpoint, '/content/drive/My Drive/Colab Notebooks/carsdata/my_checkpoint1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PM9BMpgxK5pe"
   },
   "source": [
    "## Step 6: Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H3uxYcS4Lo0D"
   },
   "outputs": [],
   "source": [
    "# Write a function that loads a checkpoint and rebuilds the model\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "\n",
    "    checkpoint = torch.load(filepath)\n",
    "    \n",
    "    #model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dbACQoOmN1Dp",
    "outputId": "b913c74c-7624-4c50-80d6-b6aa105cd5f0"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Loading model\n",
    "model = load_checkpoint('/content/drive/My Drive/Colab Notebooks/carsdata/my_checkpoint1.pth')\n",
    "# Checking model i.e. should have 196 output units in the classifier\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxpeelnTkWLg"
   },
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFnIGydILDh8"
   },
   "source": [
    "## Step 7: Predict the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4-5e6f-XzPW"
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \n",
    "    # Process a PIL image for use in a PyTorch model\n",
    "\n",
    "    # Converting image to PIL image using image file path\n",
    "    pil_im = Image.open(f'{image}' + '.jpg')\n",
    "\n",
    "    # Building image transform\n",
    "    transform = transforms.Compose([transforms.Resize((244,244)),\n",
    "                                    #transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                         [0.229, 0.224, 0.225])]) \n",
    "    \n",
    "    # Transforming image for use with network\n",
    "    pil_tfd = transform(pil_im)\n",
    "    \n",
    "    # Converting to Numpy array \n",
    "    array_im_tfd = np.array(pil_tfd)\n",
    "    \n",
    "    return array_im_tfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rH4Elba-CNnD"
   },
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "1t3KpW8MCdD1",
    "outputId": "5b16dd26-b5ac-4138-9321-32ec8d47accf"
   },
   "outputs": [],
   "source": [
    "imshow(process_image(train_dir + 'bmw 3 2019'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3tTW5LeC5UJ"
   },
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    # Implement the code to predict the class from an image file   \n",
    "    \n",
    "    # Loading model - using .cpu() for working with CPUs\n",
    "    loaded_model = load_checkpoint(model).cpu()\n",
    "    loaded_model.to('cuda')\n",
    "    # Pre-processing image\n",
    "    img = process_image(image_path)\n",
    "    # Converting to torch tensor from Numpy array\n",
    "    img_tensor = torch.from_numpy(img).type(torch.FloatTensor)\n",
    "    # Adding dimension to image to comply with (B x C x W x H) input of model\n",
    "    img_add_dim = img_tensor.unsqueeze_(0)\n",
    "\n",
    "    # Setting model to evaluation mode and turning off gradients\n",
    "    loaded_model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Running image through network\n",
    "        output = loaded_model.forward(img_add_dim)\n",
    "        \n",
    "    #conf, predicted = torch.max(output.data, 1)   \n",
    "    probs_top = output.topk(topk)[0]\n",
    "    predicted_top = output.topk(topk)[1]\n",
    "    \n",
    "    # Converting probabilities and outputs to lists\n",
    "    conf = np.array(probs_top)[0]\n",
    "    predicted = np.array(predicted_top)[0]\n",
    "        \n",
    "    #return probs_top_list, index_top_list\n",
    "    return conf, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "mnMLifs1xkFH",
    "outputId": "43f660ac-f595-4844-c523-2b279ec0b018"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16074/2429347773.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# tie the class indices to their names\n",
    "\n",
    "def find_classes(dir):\n",
    "    classes = os.listdir(dir)\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx\n",
    "classes, c_to_idx = find_classes(data_dir+\"train\")\n",
    "\n",
    "print(classes, c_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vArJuuBLMorV"
   },
   "source": [
    "## Step 8: Show the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "zB2xQXIx3ONA",
    "outputId": "d04fb87c-3be4-42cb-8d3e-94c4d8ddc856"
   },
   "outputs": [],
   "source": [
    "model_path = '/content/drive/My Drive/Colab Notebooks/my_checkpoint1.pth'\n",
    "image_path = data_dir + 'bmw 3 2010'\n",
    "\n",
    "\n",
    "conf1, predicted1 = predict(image_path, model_path, topk=5)\n",
    "\n",
    "print(conf1)\n",
    "print(classes[predicted1[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tztcZ6fQV1O7"
   },
   "outputs": [],
   "source": [
    "# Testing predict function\n",
    "\n",
    "# Inputs are paths to saved model and test image\n",
    "model_path = '/content/drive/My Drive/Colab Notebooks/my_checkpoint1.pth'\n",
    "carname = 'Hyundai Veloster Hatchback 2012'\n",
    "image_path = data_dir + carname\n",
    "\n",
    "\n",
    "conf2, predicted1 = predict(image_path, model_path, topk=5)\n",
    "# Converting classes to names\n",
    "names = []\n",
    "for i in range(5):\n",
    "  \n",
    "    names += [classes[predicted1[i]]]\n",
    "\n",
    "# Creating PIL image\n",
    "image = Image.open(image_path+'.jpg')\n",
    "\n",
    "# Plotting test image and predicted probabilites\n",
    "f, ax = plt.subplots(2,figsize = (6,10))\n",
    "\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title(carname)\n",
    "\n",
    "y_names = np.arange(len(names))\n",
    "ax[1].barh(y_names, conf2/conf2.sum(), color='darkblue')\n",
    "ax[1].set_yticks(y_names)\n",
    "ax[1].set_yticklabels(names)\n",
    "ax[1].invert_yaxis() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3w-rrr1Ey-5j"
   },
   "outputs": [],
   "source": [
    "def plot_solution(cardir, model):\n",
    "  # Testing predict function\n",
    "\n",
    "  # Inputs are paths to saved model and test image\n",
    "  model_path = '/content/drive/My Drive/Colab Notebooks/my_checkpoint1.pth'\n",
    "  image_path = test_dir + cardir\n",
    "  carname = cardir.split('/')[1]\n",
    "\n",
    "  conf2, predicted1 = predict(image_path, model_path, topk=5)\n",
    "  # Converting classes to names\n",
    "  names = []\n",
    "  for i in range(5):\n",
    "  \n",
    "      names += [classes[predicted1[i]]]\n",
    "\n",
    "\n",
    "  # Creating PIL image\n",
    "  image = Image.open(image_path+'.jpg')\n",
    "\n",
    "  # Plotting test image and predicted probabilites\n",
    "  f, ax = plt.subplots(2,figsize = (6,10))\n",
    "\n",
    "  ax[0].imshow(image)\n",
    "  ax[0].set_title(carname)\n",
    "\n",
    "  y_names = np.arange(len(names))\n",
    "  ax[1].barh(y_names, conf2/conf2.sum(), color='darkblue')\n",
    "  ax[1].set_yticks(y_names)\n",
    "  ax[1].set_yticklabels(names)\n",
    "  ax[1].invert_yaxis() \n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "LjKmsvWD21Z5",
    "outputId": "e4b8e62e-5008-4661-dd65-bc17d0a10145"
   },
   "outputs": [],
   "source": [
    "cardir='/BMW 3 Series Sedan 2012/06582'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "UX117BuN6ySN",
    "outputId": "7a633f1c-c7b9-4361-d608-4ebad81b2af6"
   },
   "outputs": [],
   "source": [
    "cardir='/BMW 3 Series Sedan 2012/06544'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "mV5KWYT37U77",
    "outputId": "8847ba5c-8b21-40b2-a699-10d6ce519e09"
   },
   "outputs": [],
   "source": [
    "cardir='/BMW M5 Sedan 2010/03529'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "kkGdcQis7gIs",
    "outputId": "b1c948b4-c5c1-4ddc-bbca-62302c768b51"
   },
   "outputs": [],
   "source": [
    "cardir='/BMW X6 SUV 2012/02891'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "colab_type": "code",
    "id": "g_DkjlIQ7tqz",
    "outputId": "538b2dd1-29e7-41aa-c6ac-88cfd11a46e8"
   },
   "outputs": [],
   "source": [
    "cardir='/BMW X5 SUV 2007/03310'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "colab_type": "code",
    "id": "8jaUcCQ-73Ga",
    "outputId": "1cbf49cf-55c2-4fac-e878-322370440830"
   },
   "outputs": [],
   "source": [
    "cardir='/Hyundai Veloster Hatchback 2012/06652'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "cATjCLma7_ua",
    "outputId": "450db199-94a1-4eff-80cb-a8e01467b755"
   },
   "outputs": [],
   "source": [
    "cardir='/Volkswagen Golf Hatchback 2012/06875'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "1G_qZ0Sa8Jdh",
    "outputId": "eb46c5b4-fa42-4982-84e0-086e6f0bd4e4"
   },
   "outputs": [],
   "source": [
    "cardir='/Hyundai Tucson SUV 2012/07220'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpOpoVC68Rpa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of cars model classifier.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
